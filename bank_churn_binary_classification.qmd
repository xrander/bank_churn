---
title: "Bank Churn Binary Classification"
author: "Olamide Adu"
format: html
---

# Introduction

This is a beginner-friendly note to predict bank churning. Bank churning refers to the practice of repeated opening and closing of bank accounts typically to take advantage of financial incentives like sign-up bonuses, promotional offers and so on, or any other motives for opening and closing multiple accounts.

## Aim of Project

The aim of this project is to predict the bank customers that will churn. Three models will be trained to predict customer churning. The models are:

-   logistic regression,

-   decision trees and,

-   random forest

### Load Libraries

```{r}
#| label: load-libraries
#| warning: false
#| message: false
#| results: hide

library(tidyverse)
library(ggthemes) 
library(tidymodels)
library(janitor)
library(GGally)
library(patchwork)
library(wordcloud2)
library(webshot2)
library(gt)
library(scales)
library(ggridges)
```

## Data Definition

The bank customer churn dataset is a commonly used dataset for predicting customer churn in the banking industry. It contains information on bank customers who either left the bank or continue to be a customer. The dataset includes the following attributes:

1.  **Customer ID**: A unique identifier for each customer

2.  **Surname**: The customer's surname or last name

3.  **Credit Score**: A numerical value representing the customer's credit score

4.  **Geography**: The country where the customer resides (France, Spain or Germany)

5.  **Gender**: The customer's gender (Male or Female)

6.  **Age**: The customer's age.

7.  **Tenure**: The number of years the customer has been with the bank

8.  **Balance**: The customer's account balance

9.  **NumOfProducts**: The number of bank products the customer uses (e.g., savings account, credit card)

10. **HasCrCard**: Whether the customer has a credit card (1 = yes, 0 = no)

11. **IsActiveMember**: Whether the customer is an active member (1 = yes, 0 = no)

12. **EstimatedSalary**: The estimated salary of the customer

13. **Exited**: Whether the customer has churned (1 = yes, 0 = no).

### Import the data

```{r}
#| label: pkg-import-data
#| message: false

train_data <- read_csv("data/train.csv") |> 
  clean_names() |> 
  mutate(exited = factor(exited))

test_data <- read_csv("data/test.csv") |> 
  clean_names()

dim(train_data)
dim(test_data)
```

The `train_data` is having 165034 rows and 14 columns while the `test_data` is having 110023 rows and 13 columns

```{r}
#| label: tbl-data-frame-comparison
#| tbl-cap: |
#|  Comparison between the variable types between the train and test data

compare_df_cols(train_data, test_data) |> 
  gt()
```

@tbl-data-frame-comparison shows only the target variable missing in the test data

# Exploratory Data Analysis

### Target Variable

```{r}
#| label: fig-churned-and-retained-members
#| layout-ncol: 2
#| fig-cap: Frequency of churned and retained account
#| fig-subcap:
#|  - "churned and retained members"
#|  - "churned and retained members according to countries"


train_data |> 
  mutate(exited = factor(exited, levels = c(0, 1), labels = c("No", "Yes"))) |> 
  ggplot(aes(exited)) +
  geom_bar(fill = c("brown", "orange")) +
  theme_pander() +
  labs(
    x = "Churned",
    y = "Count",
    title = "Retained account is more than churned account",
  ) +
  scale_y_continuous(labels = label_comma())

train_data |> 
  mutate(exited = factor(exited, levels = c(0, 1), labels = c("No", "Yes"))) |> 
  ggplot(aes(exited, fill = geography)) +
  geom_bar(position = "dodge") +
  theme_pander() +
  labs(
    x = "Churned",
    y = "Count",
    fill = "Geography",
    title = "France banks have more members that other banks",
    subtitle = "Germany would have higher churn-rate than other countries"
  )
```

@fig-churned-and-retained-members-1 reveals there are more retained accounts than churned accounts, while France is having more churned account than the other region, Germany seems to be close, and have less population than France, @fig-churned-and-retained-members-2.

```{r}
#| label: fig-proportion-of-exited-customer
#| layout-ncol: 2
#| fig-cap: Proportion of Churned Customer
#| fig-subcap:
#|     - "credit card"
#|     - "active member" 
#| fig-alt: |
#|  - Bar plot of customers bank account, a: total proportion of churned customers
#|  orange bar represents members that have churned, and black represents members that
#|  have not churned, b: Proportion of churned customers according to
#|  how active they are in  using the bank and its services.

train_data |> 
  mutate(
    exited = factor(exited, levels = c(0, 1), labels = c("No", "Yes")),
    has_cr_card = factor(has_cr_card, levels = c(0, 1), labels = c("No", "Yes"))
    ) |> 
  ggplot(aes(exited, after_stat(prop), group = has_cr_card, fill = has_cr_card)) +
  geom_bar(position = "dodge") +
  scale_fill_tableau() +
  labs(
    x = "Churned", y = "Proportion", 
    fill = "Has credit card",
    title = "Owning a credit card doesn't influence churning"
  ) +
  scale_y_continuous(labels = label_percent()) +
  theme_clean()
  
train_data |> 
  mutate(
    exited = factor(exited, levels = c(0, 1), labels = c("No", "Yes")),
    is_active_member = factor(is_active_member, levels = c(0, 1), labels = c("No", "Yes"))
    ) |>
  ggplot(
    aes(exited, after_stat(prop), 
        group = is_active_member, 
        fill = is_active_member)
  ) +
  geom_bar(position = "dodge") +
  scale_fill_tableau() +
  labs(
    x = "Churned", y = "Proportion", 
    fill = "Active member",
    title = "Inactive members churn more than active members"
  ) +
  scale_y_continuous(labels = label_percent()) +
  theme_clean()
```

@fig-proportion-of-exited-customer-1 shows about 20% percent of the customers churning either if they have credit card or not, and @fig-proportion-of-exited-customer-2 shows a clear members that are not active members churning more than active members.

```{r}
#| label: fig-exited-est-sal-credit-score
#| fig-cap: Scatter plot of estimated salary and credit score of members across the three countries.

train_data |> 
  ggplot(aes(estimated_salary, credit_score, color = factor(exited))) +
  geom_point() + 
  scale_color_tableau(labels = c("No", "Yes")) +
  facet_wrap(~geography) +
  labs(
    x = "Estimated Salary",
    y = "Credit Score",
    fill = "Churned",
    title = "Chruning is not affected by credit score and estimated salary",
    subtitle = "Germany has high churn compared to France and Spain"
  ) +
  scale_x_continuous(labels = label_currency(prefix = "â‚¬")) +
  theme_pander() +
  theme(axis.text.x = element_text(angle = 45))
```

@fig-exited-est-sal-credit-score shows German members churn at all ranges of estimated salary and credit score.

### Feature Variable

#### Categorical Variables

```{r}
#| label: fig-customer-word-cloud
#| fig-cap: Word cloud of customers according to the number of churned accounts they own

customer_name <- train_data |> 
  filter(exited == 1) |> 
  group_by(surname) |> 
  count() |> 
  ungroup() |> 
  rename(freq = n) |> 
  arrange(desc(freq))

wordcloud2(customer_name, size =1.6, color = "random-light", backgroundColor = "black")
```

@fig-customer-word-cloud shows customers having churned account. The account under the name Hsia have churned the most.

```{r}
#| label: fig-gender-distribution
#| fig-cap: |
#|  Distribution of gender shows that there are more male members than female members
#| fig-subcap: 
#|  - "General member  population according to sex"
#|  - "Member population according to country"

train_data |> 
  ggplot(aes(gender, fill = gender)) +
  geom_bar(show.legend = F) +
  labs(x = "gender", y = "Count", title = "Male members are more than females") +
  scale_fill_calc() +
  theme_pander()

train_data |> 
  ggplot(aes(gender, fill = geography)) +
  geom_bar(position = "dodge") +
  labs(
    x = "Age",
    y = "Count",
    fill = "Geography",
    title = "Age distribution across countries"
  ) +
  scale_fill_calc() +
  theme_pander()

```

@fig-gender-distribution shows there are more male customer than female customers

```{r}
#| label: fig-active-member
#| layout-ncol: 2
#| fig-cap: Members activity status
#| fig-subcap: 
#|   - "Members status if active or not"
#|   - "Members status according to their gender"

train_data |> 
  mutate(is_active_member = factor(
    is_active_member,
    levels = c(0, 1),
    labels = c("No", "Yes"))
  ) |> 
  ggplot(aes(is_active_member, fill = is_active_member)) +
  geom_bar(show.legend = F) +
  labs(
    x = "Active member",
    y = "Count",
    title = "No difference in the count of active and inactive members"
  ) +
  scale_fill_tableau() +
  theme_pander()

train_data |> 
  mutate(is_active_member = factor(
    is_active_member,
    levels = c(0, 1),
    labels = c("No", "Yes"))
  ) |> 
  ggplot(aes(is_active_member, fill = gender)) +
  geom_bar(position = "dodge") +
  labs(
    title = "Active members according to sex",
    fill = "Gender",
    x = "Active member", y = "count"
  ) +
  scale_fill_colorblind() +
  theme_pander()
```

@fig-active-member shows no difference in the number of members activity, even when differentiated by their gender @fig-active-member-2.

```{r}
#| label: fig-has-credit-card-plot
#| fig-cap: Members with Credit Cards

train_data |> 
  mutate(has_cr_card = factor(has_cr_card, levels = c(0, 1), labels = c("No", "Yes"))) |> 
  ggplot(aes(has_cr_card, fill = has_cr_card)) +
  geom_bar(show.legend = F) +
  labs(x = "Has Credit Card", y = "Count") +
  scale_fill_tableau() +
  theme_pander()
```

#### Numeric Variables

```{r}
#| label: fig-age-distribution
#| fig-width: 7
#| fig-cap: Age distribution of customers
#| fig-subcap: 
#|  - "General age distribution"
#|  - "Age distribution according to sex"

age_distribution <- train_data |> 
  ggplot(aes(age)) +
  geom_histogram(binwidth = 5, fill = "tomato3") +
  geom_density(stat = "bin", binwidth = 5, col = "black") +
  expand_limits(x = c(0, 100)) +
  labs(
    x = "Age",
    title = "General age distribution",
    y = "Count"
  ) +
  theme_pander() +
  theme(plot.title = element_text(size = 12),
        plot.subtitle = element_text(size = 8))

age_distribution_sex <- train_data |> 
  ggplot(aes(age, col = gender)) +
  geom_freqpoly(binwidth = 15) +
  labs(
    x = "Age",
    y = "",
    col = "Gender",
    title = "Members 30 to 40 are higher for both sex",
    subtitle = "Males are more than Females across all ages"
  ) +
  scale_color_calc() +
  theme_pander() +
  theme(plot.title = element_text(size = 12),
        plot.subtitle = element_text(size = 8))

age_distribution + age_distribution_sex
```

The highest number of account owners are between age 30 to 40 as show in @fig-age-distribution-1, with male members being more than female members across all ages @fig-age-distribution-2 .

```{r}
#| label: fig-credit-score-density
#| layout-ncol: 2
#| fig-cap: Credit score across regions
#| fig-subcap: 
#|   - "a: Credit score distribution"
#|   - "b: Credit score according to geography"
#| warning: false
#| message: false

train_data |> 
  ggplot(aes(credit_score)) +
  geom_histogram(binwidth = 50, alpha = 0.7, fill = "tomato3") +
  geom_density(stat = "bin", col = "black", binwidth = 50) +
  labs(
    x = "Credit Score",
    y = "Density", 
    title = "General credit score distribution"
  ) +
  theme_pander()

train_data |> 
  ggplot(aes(credit_score, geography, fill = geography)) +
  geom_density_ridges(alpha = 0.5, show.legend = F) +
  labs(x = "Credit Score", y = "Geography") +
  scale_fill_calc() +
  labs(
    title = "Regional credit score distribution",
    subtitle = "No difference in credit score distribution across regions"
  ) +
  theme_pander()
```

@fig-credit-score-density-2 shows no differences in the credit score across regions and in general @fig-credit-score-density-1

```{r}
#| label: fig-tenure-members
#| fig-cap: Members tenure
train_data |> 
  mutate(tenure = factor(tenure)) |> 
  ggplot(aes(fct_infreq(tenure), fill = tenure)) +
  geom_bar(show.legend = F) +
  labs(x = "Tenure", y = "count", title = "Count of members according to tenure") +
  scale_fill_calc() +
  theme_pander()
```

There's a good distribution of old and new members @fig-tenure-members

```{r}
#| label: fig-est-salary
#| layout-ncol: 3
#| fig-cap: Estimated salary distribution
#| fig-subcap: 
#|   - "General estimated salary distribution"
#|   - "Estimated salary distribution according to gender"
#|   - "Estimated salary distribution according to region"

train_data |> 
  ggplot(aes(estimated_salary)) +
  geom_histogram(binwidth = 10000, fill = "tomato3", alpha = 0.5) +
  geom_density(stat = "bin", binwidth = 10000, col = "black") +
  labs(
    x = "Estimated salary",
    y = " Count",
    title = "Multimodal estimated salary distribution"
  ) +
  theme_pander()

train_data |> 
  ggplot(aes(estimated_salary, gender, fill = gender)) +
  geom_density_ridges(alpha = 0.4) +
  labs(
    x = "Estimated salary",
    y = "Density",
    fill = "Gender",
    title = "Estimated salary distribution of the genders"
  ) +
  scale_x_continuous(labels = label_currency(prefix = "â‚¬")) +
  theme_pander() +
  theme(legend.position = "none")

train_data |> 
  ggplot(aes(estimated_salary, geography, fill = geography)) +
  geom_density_ridges(alpha = 0.4) +
  labs(
    x = "Estimated salary",
    y = "Density",
    fill = "Geography",
    title = "Estimated salary distribution of according to regions"
  ) +
  scale_x_continuous(labels = label_currency(prefix = "â‚¬")) +
  theme_pander() +
  theme(legend.position = "none")
```

@fig-est-salary showing multimodal distribution of estimated salary.

#### Correlation Plot

```{r}
#| label: correlation-plot
#| message: false
#| warning: false
#| fig-cap: Correlation plot

ggcorr(train_data)
```

# Model Workflow

Three models were used for predicting members that churned. They are:

-   logistic model

-   decision trees

-   random forest

The metrics for evaluation will only be the roc_auc

## Data Pre-processing for Modelling

```{r}
#| label: data preparation

train_data_preproc <- train_data |> 
  select(!c(id, customer_id, surname)) |> 
  mutate_if(is_character, factor)

head(train_data_preproc)
```

## Data Splitting

The data is split into three parts: - A training set - A testing set - A validation set

```{r}
#| label: data-splitting

set.seed(234)

train_data_split <- initial_split(train_data_preproc, prop = c(.8), strata = exited)

training_data <- training(train_data_split)
validation_data <- testing(train_data_split)
```

## Model Development

The engine to be used for the pre-selected algorithms, will be shown below.

```{r}
#| label: algorithms-to-be-used
log_reg_model  <- 
  logistic_reg() |> 
  set_engine("glm")

decision_tree_model <-
  decision_tree(
    tree_depth = tune(),
    cost_complexity = tune()
  ) |> 
  set_engine("rpart") |> 
  set_mode("classification")

rf_model <- 
  rand_forest(
    trees = 1000,
    mtry = tune(),
    min_n = tune()
  ) |> 
  set_engine("ranger") |> 
  set_mode("classification")
```

### Feature Engineering

Some feature engineering will be carried out for the different models, based on their specifications

```{r}
#| label: feature-engineering
log_reg_rec <-
  recipe(
    exited ~ ., 
    data = training_data
  )  |> 
  step_dummy(geography) |>
  step_zv()

decision_tree_rec <- 
  recipe(exited ~ .,
         data = training_data) |> 
  step_nzv()

rf_rec <-
  recipe(
    exited ~ .,
  data = training_data
  ) |> 
  step_zv()
```

Recipe object and model specification will be added to each model workflow

```{r}
#| label: model workflow

log_reg_wf <-
  workflow() |> 
  add_model(log_reg_model) |> 
  add_recipe(log_reg_rec)
  

rand_forest_wf <-
  workflow() |> 
  add_recipe(rf_rec) |> 
  add_model(rf_model)

decision_tree_wf <-
  workflow() |> 
  add_recipe(decision_tree_rec) |> 
  add_model(decision_tree_model)

```

## Logistic_regression

```{r}
#| label: fit-models
#| message: false

log_reg_fit <- 
  log_reg_wf |>  
  fit(training_data)

```

Next, we test the fit on the validation set.

```{r}
#| label: log-regression-prediction

log_reg_validation_pred <- predict(log_reg_fit, validation_data, type = "class") |> 
  bind_cols(validation_data) |> 
  relocate(.pred_class, .after = exited)
```


```{r}
#| label: log-regression-confusion-matrix
conf_mat(log_reg_validation_pred, truth = exited, estimate = .pred_class)
```
There are more false positive than false negative. The model predicts non-event better than event, but the accuracy is 83%
```{r}
#| label: tbl-log-reg-accuracy
#| tbl-cap: Logistic regression accuracy
#| 
accuracy(log_reg_validation_pred, truth = exited, estimate = .pred_class)
```


```{r}
#| label: fig-roc-auc-log-reg
#| fig-cap: Area under the curve of Logistic regression
log_reg_validation_pred |> 
  mutate(.pred_class = as.numeric(.pred_class)) |> 
  roc_curve(exited, .pred_class) |> 
  autoplot() +
  labs(
    title = str_wrap(
      "Logistic regression shows low predictive capacity for churned class",
      width  = 70)
  ) + 
  theme_pander()
```

Area under the curve, @fig-roc-auc-log-reg shows the predictive capability for churning is below 50%, while accuracy is high @tbl-log-reg-accuracy, this can be the ability to predict retention, which is not our interest. We will check the other models to see which will give our desired result

```{r}
#| label: cross-fold validation
training_data_folds <- vfold_cv(training_data, v = 5, strata = exited)
```


## Decision Trees
For the decision tree, we will set a grid a not too complex, and this is due to computational resources. After that we will tune or model, collect their metrics and evaluate their performance. Parallel computing will be employed to reduce training time time.

### Fit Regular Grid
```{r}
#| label: decision-tree-grid
set.seed(345)

tree_grid <- 
  grid_regular(
    cost_complexity(),
    tree_depth(),
    levels = 5
  )

tree_grid |> 
  count(tree_depth)
```

### Tune Grid
```{r}
#| label: decision-tune-tuning
set.seed(234)
doParallel::registerDoParallel(cores = 5)
dt_tune <-
  tune_grid(
    decision_tree_wf,
    grid = tree_grid,
    resamples = training_data_folds
  )
```


```{r}
#| label: decision-tune-metric

dt_tune |> 
  collect_metrics() |> 
  head(n = 10)
```
Visualizing the result will be better than the normal print
```{r}
#| label: fig-tree-grid-viz
#| fig: Grid search tune results for random forest

dt_tune |> 
  collect_metrics() |> 
  filter(.metric == "roc_auc") |> 
  mutate(tree_depth = factor(tree_depth)) |> 
  ggplot(aes(cost_complexity, mean, color = tree_depth)) +
  geom_line(linewidth = 1, alpha = 0.4) +
  labs( 
    x = "Cost Complexity",
    y = "AUC",
    col = "Tree depth",
    title = "Model improves as tree depth increases",
    subtitle = str_wrap("Tree depth 15 performed well, but 11 is the best", width = 50)
  ) +
  geom_point(size = 2) +
  scale_x_log10(labels = label_number()) +
  scale_color_colorblind() +
  theme_clean() +
  expand_limits(y = c(0.5, 0.9)) +
  theme(legend.position = "bottom")
  
```

Our short tree with depth of 1 performed bad across all values of `cost_complexity`. The model improves as tree depth increases, but the best depth is 11 and not the maximum tree depth of 15 @fig-tree-grid-viz. The top 5 candidates models are show below.

```{r}
#| label: decision-tress-best-parameter
dt_tune |> 
  show_best("roc_auc")
```

We will select the best of the hyperparameter values and use it to finalize our model

```{r}
#| label: best-decision-tree-selection
best_tree <- dt_tune |> 
  select_best("roc_auc")

best_tree
```

Before we proceed with finalizing, we will fit a random forest tree and see how it performs compare it to the decision tree model, then finalize on which is the best.

## Random Forest
The right values to use, when training a single model is unknown, but we can train a group and see which turns out best. 

### Data Sharing for Random Forest
Our training data is large, more than 132926 rows and 11 columns, a sample of this data should be collected, and be used to train the random forest model. Parallelization will also be used here to speed up to processing time. 

```{r}
#| label: random-forest-resamples
set.seed (222)
rand_for_resamples <- initial_split(training_data, prop = 0.1, strata = exited)

rand_for_resamples <- training(rand_for_resamples)

rand_for_resamples <- vfold_cv(rand_for_resamples, v = 10)
```

### Tuning Random Forest
```{r}
#| label: random-forest-tuning
set.seed(456)
doParallel::registerDoParallel(cores = 5)

rf_tune <-
  tune_grid(
    rand_forest_wf,
    resamples = rand_for_resamples,
    grid = 20
  )
```
Let's see the result
```{r}
#| label: pretuning-rand-forest

rf_tune |> 
  collect_metrics() |> 
  filter(.metric == "roc_auc") |> 
  select(mtry, min_n, mean) |> 
  pivot_longer(
    mtry:min_n,
    values_to = "value",
    names_to = "parameter"
  ) |> 
  ggplot(aes(value, mean, col = parameter)) +
  geom_point() +
  labs(
    x = "Value",
    y = "AUC",
    title = "Low mtry and high min_n are likely to make good model"
  ) +
  facet_wrap(~parameter, scales = "free") +
  scale_color_colorblind() +
  theme_clean()
```

### Tune Random Forest with Regular Grid

From the plot above, it seems low mtry (from 2 to 5) are good and high min_n (25 to 35) are good. We should a set range between this values using grid_regular for tuning one more time.
```{r}
#| label: regular-grid-search-rand-forest

rf_grid <- 
  grid_regular(
    min_n(range = c(25, 35)),
    mtry(range = c(2, 6)),
    levels = 5
  )

rf_grid
```
Now we retune with the regular grid.

```{r}
#| label: random-forest-model-grid-tuning

set.seed(347)

rand_forest_tune_reg <-
  tune_grid(
    rand_forest_wf,
    resamples = rand_for_resamples,
    grid = rf_grid
  )
```

```{r}
#| label: tune-performance-visualization
rand_forest_tune_reg |> 
  collect_metrics() |> 
  filter(.metric == "roc_auc") |> 
  mutate(mtry = factor(mtry)) |> 
  ggplot(aes(min_n, mean, col = mtry)) +
  geom_point() +
  geom_line() +
  labs(
    y = "AUC", 
    title = "Model performance reduces as mtry increases",
    subtitle = "Model performance generally increases as min_n increases"
  ) +
  theme_clean()
```
The best combination of parameters is when mtry is 2 and min_n is 30, but this can likely lead to underfitting (pretty low mtry of 2) as only two features are evaluated as candidates for each split.

```{r}
#| label: tbl--roc-auc-min_n-mtry
#| table: roc-auc-rand-forest
rand_forest_tune_reg |> 
  show_best("roc_auc", n = 10)
```

```{r}
#| label: select-best-rand-forest-param

best_forest <- 
  rand_forest_tune_reg |> 
  select_best("roc_auc")
```



## Model Choice decision
The best model seems to be the random forest model using the `roc_auc` to evaluate, but giving the tendency to for the random underfit, the decision tree will be selected.
```{r}
#| label: final-model
final_tree <- finalize_model(
  decision_tree_model,
  best_tree
)

final_tree
```
We can check the variable importance, from our model. We will first prep and juice our recipe for decision tree.

```{r}
#| label: juice-prep-recipe
dec_prep <- prep(decision_tree_rec)

dec_tree <- juice(dec_prep)
```


### Feature Importance
```{r}
#| label: fig-feature-importance
#| message: false
#| fig-cap: Variable of importance
library(vip)

tree_fit <- final_tree |> 
  set_engine("rpart") |> 
  fit(exited ~ ., data = dec_tree)

vip(tree_fit, aes = list(fill = "mediumaquamarine")) +
  labs(
    x = "importance",
    y = "Features",
    title = "Feature importance"
  ) +
  theme_clean()
```
Age, num_of_products, balance, and is_active_member are the most important features in the model @fig-feature-importance.

The model is finalized, we need to finalize the workflow, then make the last fit

### Finalizing Models
```{r}
#| label: finalize-workflow-and-last-fit

tree_final_wf <- workflow() |> 
  add_recipe(decision_tree_rec) |> 
  add_model(final_tree)

tree_final_fit <- 
  last_fit(
    tree_final_wf,
    train_data_split
  )
```


```{r}
#| label: final-fit-metric
tree_final_fit |> 
  collect_metrics("roc_auc")
```

The metrics is good and we did not overfit during tuning.

```{r}
#| label: model-predicitions
#| message = false

tree_final_fit |> 
  collect_predictions() |> 
  mutate(prediction_status = case_when(
    exited == .pred_class ~ "Correct",
    .default = "Incorrect"
  )) |> 
  bind_cols(validation_data) |> 
  clean_names() |>
  filter(exited_19 == 1) |> 
  ggplot(aes(estimated_salary, credit_score, color = prediction_status)) +
  geom_point() + 
  scale_color_tableau() +
  facet_wrap(~geography) +
  labs(
    x = "Estimated Salary",
    y = "Credit Score",
    col = "Prediction",
    title = "Prediction of Exited members",
    subtitle = "Model have lots of incorrect predicitions in France"
  ) +
  scale_x_continuous(labels = label_currency(prefix = "â‚¬")) +
  theme_pander() +
  theme(axis.text.x = element_text(angle = 320))
```

# 